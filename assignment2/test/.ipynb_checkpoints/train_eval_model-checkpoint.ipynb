{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train model and eval model helpers.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from models.linear_regression import LinearRegression\n",
    "\n",
    "\n",
    "def train_model(processed_dataset, model, learning_rate=0.001, batch_size=16,\n",
    "                num_steps=1000, shuffle=True):\n",
    "    \"\"\"Implements the training loop of stochastic gradient descent.\n",
    "\n",
    "    Performs stochastic gradient descent with the indicated batch_size.\n",
    "    If shuffle is true:\n",
    "        Shuffle data at every epoch, including the 0th epoch.\n",
    "    If the number of example is not divisible by batch_size, the last batch\n",
    "    will simply be the remaining examples.\n",
    "\n",
    "    Args:\n",
    "        processed_dataset(list): Data loaded from io_tools\n",
    "        model(LinearModel): Initialized linear model.\n",
    "        learning_rate(float): Learning rate of your choice\n",
    "        batch_size(int): Batch size of your choise.\n",
    "        num_steps(int): Number of steps to run the updated.\n",
    "        shuffle(bool): Whether to shuffle data at every epoch.\n",
    "    Returns:\n",
    "        model(LinearModel): Returns a trained model.\n",
    "    \"\"\"\n",
    "    # Perform gradient descent.\n",
    "    count = 0\n",
    "    while shuffle is True:\n",
    "        i = 0\n",
    "        sizeofds = processed_dataset[0].shape[0] \n",
    "        shuf = np.arange(sizeofds)\n",
    "        np.random.shuffle(shuf)\n",
    "        processed_dataset[0][shuf]\n",
    "        processed_dataset[1][shuf]\n",
    "        while i + batch_size <= sizeofds:\n",
    "            count = count + 1\n",
    "            if count > num_steps:\n",
    "                break\n",
    "            x_batch = processed_dataset[0][i:i+batch_size,:]\n",
    "            y_batch = processed_dataset[1][:, i:i+batch_size]\n",
    "            update_step(x_batch, y_batch, model, learning_rate)\n",
    "            i = i + batch_size\n",
    "            \n",
    "        if count > num_steps:\n",
    "            break\n",
    "        count = count + 1\n",
    "        x_batch = processed_dataset[0][i:sizeofds-i,:]\n",
    "        y_batch = processed_dataset[1][:,i:sizeofds-i]\n",
    "        update_step(x_batch, y_batch, model, learning_rate)\n",
    "    return model\n",
    "\n",
    "\n",
    "def update_step(x_batch, y_batch, model, learning_rate):\n",
    "    \"\"\"Performs on single update step, (i.e. forward then backward).\n",
    "\n",
    "    Args:\n",
    "        x_batch(numpy.ndarray): input data of dimension (N, ndims).\n",
    "        y_batch(numpy.ndarray): label data of dimension (N, 1).\n",
    "        model(LinearModel): Initialized linear model.\n",
    "    \"\"\"\n",
    "    forw = model.forward(x_batch)\n",
    "    back = model.backward(forw, y_batch)\n",
    "    model.w = model.w - learning_rate * back\n",
    "\n",
    "\n",
    "def train_model_analytic(processed_dataset, model):\n",
    "    \"\"\"Computes and sets the optimal model weights (model.w).\n",
    "\n",
    "    Args:\n",
    "        processed_dataset(list): List of [x,y] processed\n",
    "            from utils.data_tools.preprocess_data.\n",
    "        model(LinearRegression): LinearRegression model.\n",
    "    \"\"\"\n",
    "    x = processed_dataset[0]\n",
    "    y = processed_dataset[1]\n",
    "    i = np.identity(x.shape[1])\n",
    "    help1 = np.linalg.inv(np.dot(x.T, x))\n",
    "    help2 = np.dot(help1, x.T)\n",
    "    model.w = np.dot(help2, y)\n",
    "\n",
    "\n",
    "def eval_model(processed_dataset, model):\n",
    "    \"\"\"Performs evaluation on a dataset.\n",
    "\n",
    "    Args:\n",
    "        processed_dataset(list): Data loaded from io_tools.\n",
    "        model(LinearModel): Initialized linear model.\n",
    "    Returns:\n",
    "        loss(float): model loss on data.\n",
    "        acc(float): model accuracy on data.\n",
    "    \"\"\"\n",
    "#     loss = None\n",
    "    f = f.forward(processed_dataset[0])\n",
    "    loss = model.totol_loss(f, processed_dataset[1])\n",
    "\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
